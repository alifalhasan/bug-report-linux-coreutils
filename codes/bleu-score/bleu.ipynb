{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZFszMCv-Im6",
        "outputId": "f82e8c72-d998-419e-c0a2-f449f41df33c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import csv\n",
        "import nltk\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAkplXJN-Im8"
      },
      "outputs": [],
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = PorterStemmer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "\n",
        "def text_cleaning(text: str) -> str:\n",
        "    text = str(text)\n",
        "\n",
        "    text = text.encode(\"ascii\", \"ignore\").decode()\n",
        "\n",
        "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip().lower()\n",
        "\n",
        "    # Tokenization\n",
        "    words = nltk.word_tokenize(text)\n",
        "\n",
        "    # POS tagging and Lemmatization\n",
        "    pos_tags = nltk.pos_tag(words)\n",
        "    pos_map = {'N': wordnet.NOUN, 'V': wordnet.VERB, 'R': wordnet.ADV, 'J': wordnet.ADJ}\n",
        "    lemmatized_words = [lemmatizer.lemmatize(word, pos_map.get(pos[0], wordnet.NOUN)) for word, pos in pos_tags]\n",
        "\n",
        "    # Stemming\n",
        "    stemmed_words = [stemmer.stem(word) for word in lemmatized_words]\n",
        "\n",
        "    return ' '.join(stemmed_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDMVl6nr-Im9"
      },
      "outputs": [],
      "source": [
        "column_manual = []\n",
        "column_llama = []\n",
        "column_qwen = []\n",
        "column_qwen_coder = []\n",
        "\n",
        "\n",
        "with open('input.csv', 'r', encoding='utf-8') as csv_file:\n",
        "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "    next(csv_reader)\n",
        "    idx = 0\n",
        "    for row in csv_reader:\n",
        "        column_manual.append(text_cleaning(row[1]))\n",
        "        column_llama.append(text_cleaning(row[2]))\n",
        "        column_qwen.append(text_cleaning(row[3]))\n",
        "        column_qwen_coder.append(text_cleaning(row[4]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DbUmgYp-Im9",
        "outputId": "89216469-f0af-4ea2-98c4-3969ac90eaa5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10.016216216216216\n"
          ]
        }
      ],
      "source": [
        "word_counter = 0\n",
        "for sentence in column_manual:\n",
        "    word_counter = word_counter + len(sentence.split())\n",
        "print(word_counter/len(column_llama))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8DfB6Ku-Im-",
        "outputId": "203d3cf4-c221-4936-feac-b5c51f5f15a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25.535135135135135\n"
          ]
        }
      ],
      "source": [
        "word_counter = 0\n",
        "for sentence in column_llama:\n",
        "    word_counter = word_counter + len(sentence.split())\n",
        "print(word_counter/len(column_llama))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ydn3rNDO-Im-",
        "outputId": "c7b90de4-9c14-45c3-83b0-b81c68e586a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14.416216216216217\n"
          ]
        }
      ],
      "source": [
        "word_counter = 0\n",
        "for sentence in column_qwen:\n",
        "    word_counter = word_counter + len(sentence.split())\n",
        "print(word_counter/len(column_llama))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDcs2UUa-Im-",
        "outputId": "941830b5-85e8-492b-8997-99340dffef06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9.92972972972973\n"
          ]
        }
      ],
      "source": [
        "word_counter = 0\n",
        "for sentence in column_qwen_coder:\n",
        "    word_counter = word_counter + len(sentence.split())\n",
        "print(word_counter/len(column_llama))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wA42nlvV-Im-",
        "outputId": "c6f29d1c-a99e-4f03-cf29-9ff5bc8abdb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average BLEU-1 score: 0.5702390962471942\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ],
      "source": [
        "# Llama-1\n",
        "llama_scores = []\n",
        "scores = []\n",
        "for i in range(len(column_manual)):\n",
        "    score = sentence_bleu([column_manual[i]], column_llama[i], weights=(1.0, 0, 0, 0))\n",
        "    scores.append(score)\n",
        "\n",
        "avg_score = sum(scores) / len(scores)\n",
        "llama_scores.append(avg_score)\n",
        "print(f\"Average BLEU-1 score: {avg_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrv0QqOX-Im_",
        "outputId": "ebd96fb5-9223-41d8-b7e5-6d4cbe858778"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average BLEU-2 score: 0.538832231561496\n"
          ]
        }
      ],
      "source": [
        "# Llama-2\n",
        "scores = []\n",
        "for i in range(len(column_manual)):\n",
        "    score = sentence_bleu([column_manual[i]], column_llama[i], weights=(0.5, 0.5))\n",
        "    scores.append(score)\n",
        "\n",
        "llama_bleu_2_scores = scores\n",
        "\n",
        "# Calculate the average BLEU score for the columns\n",
        "avg_score = sum(scores) / len(scores)\n",
        "llama_scores.append(avg_score)\n",
        "print(f\"Average BLEU-2 score: {avg_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fp2gshK-Im_",
        "outputId": "424483d3-b86e-4f95-9403-83f8449045e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average BLEU-3 score: 0.5247299625967312\n"
          ]
        }
      ],
      "source": [
        "# Llama-3\n",
        "scores = []\n",
        "for i in range(len(column_manual)):\n",
        "    score = sentence_bleu([column_manual[i]], column_llama[i], weights=(0.33, 0.33, 0.33))\n",
        "    scores.append(score)\n",
        "\n",
        "# Calculate the average BLEU score for the columns\n",
        "avg_score = sum(scores) / len(scores)\n",
        "llama_scores.append(avg_score)\n",
        "print(f\"Average BLEU-3 score: {avg_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZhWeLfR-Im_",
        "outputId": "68726ab8-7c5c-4bfd-d9df-e2d080c8e834"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average BLEU-4 score: 0.5096852104178654\n"
          ]
        }
      ],
      "source": [
        "# Llama-4\n",
        "scores = []\n",
        "for i in range(len(column_manual)):\n",
        "    score = sentence_bleu([column_manual[i]], column_llama[i], weights=(0.25, 0.25, 0.25, 0.25))\n",
        "    scores.append(score)\n",
        "\n",
        "# Calculate the average BLEU score for the columns\n",
        "avg_score = sum(scores) / len(scores)\n",
        "llama_scores.append(avg_score)\n",
        "print(f\"Average BLEU-4 score: {avg_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FhFdCSW-InA",
        "outputId": "207a7cfe-0af6-4327-9554-55b40d5d1996"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average BLEU-1 score: 0.5666314450753404\n"
          ]
        }
      ],
      "source": [
        "# Qwen-1\n",
        "scores = []\n",
        "qwen_scores = []\n",
        "for i in range(len(column_manual)):\n",
        "    score = sentence_bleu([column_manual[i]], column_qwen[i], weights=(1.0, 0, 0, 0))\n",
        "    scores.append(score)\n",
        "\n",
        "# Calculate the average BLEU score for the columns\n",
        "avg_score = sum(scores) / len(scores)\n",
        "qwen_scores.append(avg_score)\n",
        "print(f\"Average BLEU-1 score: {avg_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "QioktiSz-InA",
        "outputId": "bee937a6-df61-4f69-aac1-a0773d12a867"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average BLEU-2 score: 0.527431303558279\n"
          ]
        }
      ],
      "source": [
        "# Qwen-2\n",
        "scores = []\n",
        "for i in range(len(column_manual)):\n",
        "    score = sentence_bleu([column_manual[i]], column_qwen[i], weights=(0.5, 0.5))\n",
        "    scores.append(score)\n",
        "\n",
        "qwen_bleu_2_scores = scores\n",
        "\n",
        "# Calculate the average BLEU score for the columns\n",
        "avg_score = sum(scores) / len(scores)\n",
        "qwen_scores.append(avg_score)\n",
        "print(f\"Average BLEU-2 score: {avg_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1S-rzSV-InA",
        "outputId": "a6ab6bd6-4435-439f-eef9-b5bdf5a8954f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average BLEU-3 score: 0.5191499526212822\n"
          ]
        }
      ],
      "source": [
        "# Qwen-3\n",
        "scores = []\n",
        "for i in range(len(column_manual)):\n",
        "    score = sentence_bleu([column_manual[i]], column_qwen[i], weights=(0.33, 0.33, 0.33))\n",
        "    scores.append(score)\n",
        "\n",
        "# Calculate the average BLEU score for the columns\n",
        "avg_score = sum(scores) / len(scores)\n",
        "qwen_scores.append(avg_score)\n",
        "print(f\"Average BLEU-3 score: {avg_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMX7cdEp-InA",
        "outputId": "f27e8802-cc3d-45e6-dc6c-3b086d9e6220"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average BLEU-4 score: 0.5096336933477369\n"
          ]
        }
      ],
      "source": [
        "# Qwen-4\n",
        "scores = []\n",
        "for i in range(len(column_manual)):\n",
        "    score = sentence_bleu([column_manual[i]], column_qwen[i], weights=(0.25, 0.25, 0.25, 0.25))\n",
        "    scores.append(score)\n",
        "\n",
        "# Calculate the average BLEU score for the columns\n",
        "avg_score = sum(scores) / len(scores)\n",
        "qwen_scores.append(avg_score)\n",
        "print(f\"Average BLEU-4 score: {avg_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiGQsWg5-InB",
        "outputId": "797be89a-ffea-4ec4-b62f-0ee1608d14e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average BLEU-1 score: 0.5253905443522353\n"
          ]
        }
      ],
      "source": [
        "# Qwen-Coder-1\n",
        "qwen_coder_scores = []\n",
        "scores = []\n",
        "for i in range(len(column_manual)):\n",
        "    score = sentence_bleu([column_manual[i]], column_qwen_coder[i], weights=(1.0, 0, 0, 0))\n",
        "    scores.append(score)\n",
        "\n",
        "# Calculate the average BLEU score for the columns\n",
        "avg_score = sum(scores) / len(scores)\n",
        "qwen_coder_scores.append(avg_score)\n",
        "print(f\"Average BLEU-1 score: {avg_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2-e-Rdw-InB",
        "outputId": "9035803a-e326-44d7-f3a6-45e12baeda35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average BLEU-2 score: 0.47479109020885785\n"
          ]
        }
      ],
      "source": [
        "# Qwen-Coder-2\n",
        "scores = []\n",
        "for i in range(len(column_manual)):\n",
        "    score = sentence_bleu([column_manual[i]], column_qwen_coder[i], weights=(0.5, 0.5))\n",
        "    scores.append(score)\n",
        "\n",
        "qwen_coder_bleu_2_scores = scores\n",
        "\n",
        "# Calculate the average BLEU score for the columns\n",
        "avg_score = sum(scores) / len(scores)\n",
        "qwen_coder_scores.append(avg_score)\n",
        "print(f\"Average BLEU-2 score: {avg_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXGSJMjE-InB",
        "outputId": "df239ee6-57cc-4dbf-b578-1ff5069b1bc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average BLEU-3 score: 0.46579952886419657\n"
          ]
        }
      ],
      "source": [
        "# Qwen-Coder-3\n",
        "scores = []\n",
        "for i in range(len(column_manual)):\n",
        "    score = sentence_bleu([column_manual[i]], column_qwen_coder[i], weights=(0.33, 0.33, 0.33))\n",
        "    scores.append(score)\n",
        "\n",
        "# Calculate the average BLEU score for the columns\n",
        "avg_score = sum(scores) / len(scores)\n",
        "qwen_coder_scores.append(avg_score)\n",
        "print(f\"Average BLEU-3 score: {avg_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oA-xGegC-InB",
        "outputId": "aa37f192-e0c9-4025-d915-9adae1fcb374"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average BLEU-4 score: 0.46202555621537555\n"
          ]
        }
      ],
      "source": [
        "# Qwen-Coder-4\n",
        "scores = []\n",
        "for i in range(len(column_manual)):\n",
        "    score = sentence_bleu([column_manual[i]], column_qwen_coder[i], weights=(0.25, 0.25, 0.25, 0.25))\n",
        "    scores.append(score)\n",
        "\n",
        "# Calculate the average BLEU score for the columns\n",
        "avg_score = sum(scores) / len(scores)\n",
        "qwen_coder_scores.append(avg_score)\n",
        "print(f\"Average BLEU-4 score: {avg_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noH6jFTj-InB",
        "outputId": "d90da21d-9e1a-454b-ef0e-487fef85cd9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.5702390962471942, 0.538832231561496, 0.5247299625967312, 0.5096852104178654]\n",
            "[0.5666314450753404, 0.527431303558279, 0.5191499526212822, 0.5096336933477369]\n",
            "[0.5253905443522353, 0.47479109020885785, 0.46579952886419657, 0.46202555621537555]\n"
          ]
        }
      ],
      "source": [
        "print(llama_scores)\n",
        "print(qwen_scores)\n",
        "print(qwen_coder_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2STqhQw-InB",
        "outputId": "fa71ddde-2abf-4bef-b986-1fc3abe1aca5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "53\n",
            "11.90566037735849\n",
            "51.886792452830186\n",
            "22.641509433962263\n",
            "17.28301886792453\n"
          ]
        }
      ],
      "source": [
        "count = 0\n",
        "word_counter_manual = 0\n",
        "word_counter_llama = 0\n",
        "word_counter_qwen = 0\n",
        "word_counter_qwen_coder = 0\n",
        "\n",
        "for i in range(len(llama_bleu_2_scores)):\n",
        "    if llama_bleu_2_scores[i] < 0.3 and qwen_bleu_2_scores[i] < 0.3 and qwen_coder_bleu_2_scores[i] < 0.3:\n",
        "        count = count + 1\n",
        "        word_counter_manual = word_counter_manual + len(column_manual[i].split())\n",
        "        word_counter_llama = word_counter_llama + len(column_llama[i].split())\n",
        "        word_counter_qwen = word_counter_qwen + len(column_qwen[i].split())\n",
        "        word_counter_qwen_coder = word_counter_qwen_coder + len(column_qwen_coder[i].split())\n",
        "print(count)\n",
        "\n",
        "print(word_counter_manual/count)\n",
        "print(word_counter_llama/count)\n",
        "print(word_counter_qwen/count)\n",
        "print(word_counter_qwen_coder/count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GM02xxj-InC",
        "outputId": "e5c300c3-eb24-4377-b41f-a4c5e2853d78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "71\n",
            "6.802816901408451\n",
            "7.619718309859155\n",
            "7.323943661971831\n",
            "7.098591549295775\n"
          ]
        }
      ],
      "source": [
        "count = 0\n",
        "word_counter_manual = 0\n",
        "word_counter_llama = 0\n",
        "word_counter_qwen = 0\n",
        "word_counter_qwen_coder = 0\n",
        "\n",
        "for i in range(len(llama_bleu_2_scores)):\n",
        "    if llama_bleu_2_scores[i] > 0.5 and qwen_bleu_2_scores[i] > 0.5 and qwen_coder_bleu_2_scores[i] > 0.5:\n",
        "        count = count + 1\n",
        "        word_counter_manual = word_counter_manual + len(column_manual[i].split())\n",
        "        word_counter_llama = word_counter_llama + len(column_llama[i].split())\n",
        "        word_counter_qwen = word_counter_qwen + len(column_qwen[i].split())\n",
        "        word_counter_qwen_coder = word_counter_qwen_coder + len(column_qwen_coder[i].split())\n",
        "print(count)\n",
        "\n",
        "print(word_counter_manual/count)\n",
        "print(word_counter_llama/count)\n",
        "print(word_counter_qwen/count)\n",
        "print(word_counter_qwen_coder/count)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}