{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZFszMCv-Im6",
        "outputId": "d690d776-354b-4612-ade3-b5a5f0ef82f4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import csv\n",
        "import nltk\n",
        "import statistics\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from nltk.translate.bleu_score import sentence_bleu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fAkplXJN-Im8"
      },
      "outputs": [],
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = PorterStemmer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "\n",
        "def text_cleaning(text: str) -> str:\n",
        "    text = str(text)\n",
        "\n",
        "    text = text.encode(\"ascii\", \"ignore\").decode()\n",
        "\n",
        "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip().lower()\n",
        "\n",
        "    # Tokenization\n",
        "    words = nltk.word_tokenize(text)\n",
        "\n",
        "    # POS tagging and Lemmatization\n",
        "    pos_tags = nltk.pos_tag(words)\n",
        "    pos_map = {'N': wordnet.NOUN, 'V': wordnet.VERB, 'R': wordnet.ADV, 'J': wordnet.ADJ}\n",
        "    lemmatized_words = [lemmatizer.lemmatize(word, pos_map.get(pos[0], wordnet.NOUN)) for word, pos in pos_tags]\n",
        "\n",
        "    # Stemming\n",
        "    stemmed_words = [stemmer.stem(word) for word in lemmatized_words]\n",
        "\n",
        "    return ' '.join(stemmed_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GDMVl6nr-Im9"
      },
      "outputs": [],
      "source": [
        "column_manual = []\n",
        "column_llama = []\n",
        "column_qwen = []\n",
        "column_qwen_coder = []\n",
        "\n",
        "\n",
        "with open('input-v1.csv', 'r', encoding='utf-8') as csv_file:\n",
        "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "    next(csv_reader)\n",
        "    idx = 0\n",
        "    for row in csv_reader:\n",
        "        column_manual.append(text_cleaning(row[1]))\n",
        "        column_llama.append(text_cleaning(row[2]))\n",
        "        column_qwen.append(text_cleaning(row[3]))\n",
        "        column_qwen_coder.append(text_cleaning(row[4]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4udLQ-XaKLnV",
        "outputId": "317e5559-2220-41db-a948-ab14fd3a4240"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Manual - Average Words: 8.58252427184466, Median Words: 5.5\n",
            "Llama - Average Words: 27.87864077669903, Median Words: 11.5\n",
            "Qwen - Average Words: 14.266990291262136, Median Words: 2.5\n",
            "Qwen-Coder - Average Words: 9.37864077669903, Median Words: 0.0\n"
          ]
        }
      ],
      "source": [
        "def compute_word_stats(columns):\n",
        "    results = {}\n",
        "    for model_name, column in columns.items():\n",
        "        word_counts = [len(sentence.split()) for sentence in column]\n",
        "        average = sum(word_counts) / len(column)\n",
        "        median = statistics.median(word_counts)\n",
        "        results[model_name] = {\"average\": average, \"median\": median}\n",
        "        print(f\"{model_name} - Average Words: {average}, Median Words: {median}\")\n",
        "    return results\n",
        "\n",
        "results_word_stats = compute_word_stats({\"Manual\": column_manual, \"Llama\": column_llama, \"Qwen\": column_qwen, \"Qwen-Coder\": column_qwen_coder})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0Cd7QbxJbI4",
        "outputId": "66ff83ef-1bc3-4bc5-e8aa-f39d12d446e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Llama BLEU-1 - Avg: 0.3887, Median: 0.2059, Highest: 1.0, Lowest: 0, Overall Range: 1.0\n",
            "  Distribution: \n",
            "    <0.3: Count = 113, Percentage = 54.85%, Range = 0.2989\n",
            "    0.3 to <0.5: Count = 14, Percentage = 6.8%, Range = 0.1617\n",
            "    >=0.5: Count = 79, Percentage = 38.35%, Range = 0.5\n",
            "Llama BLEU-2 - Avg: 0.3736, Median: 0.1759, Highest: 1.0, Lowest: 0, Overall Range: 1.0\n",
            "  Distribution: \n",
            "    <0.3: Count = 115, Percentage = 55.83%, Range = 0.2673\n",
            "    0.3 to <0.5: Count = 16, Percentage = 7.77%, Range = 0.1603\n",
            "    >=0.5: Count = 75, Percentage = 36.41%, Range = 0.4951\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Llama BLEU-3 - Avg: 0.3671, Median: 0.1674, Highest: 1.0, Lowest: 0, Overall Range: 1.0\n",
            "  Distribution: \n",
            "    <0.3: Count = 116, Percentage = 56.31%, Range = 0.2789\n",
            "    0.3 to <0.5: Count = 19, Percentage = 9.22%, Range = 0.1945\n",
            "    >=0.5: Count = 71, Percentage = 34.47%, Range = 0.4967\n",
            "Llama BLEU-4 - Avg: 0.3554, Median: 0.1481, Highest: 1.0, Lowest: 0, Overall Range: 1.0\n",
            "  Distribution: \n",
            "    <0.3: Count = 119, Percentage = 57.77%, Range = 0.298\n",
            "    0.3 to <0.5: Count = 19, Percentage = 9.22%, Range = 0.1904\n",
            "    >=0.5: Count = 68, Percentage = 33.01%, Range = 0.4846\n",
            "Qwen BLEU-1 - Avg: 0.3599, Median: 0.0, Highest: 1.0, Lowest: 0, Overall Range: 1.0\n",
            "  Distribution: \n",
            "    <0.3: Count = 120, Percentage = 58.25%, Range = 0.2591\n",
            "    0.3 to <0.5: Count = 11, Percentage = 5.34%, Range = 0.1682\n",
            "    >=0.5: Count = 75, Percentage = 36.41%, Range = 0.4928\n",
            "Qwen BLEU-2 - Avg: 0.3532, Median: 0.0, Highest: 1.0, Lowest: 0, Overall Range: 1.0\n",
            "  Distribution: \n",
            "    <0.3: Count = 121, Percentage = 58.74%, Range = 0.1643\n",
            "    0.3 to <0.5: Count = 10, Percentage = 4.85%, Range = 0.1669\n",
            "    >=0.5: Count = 75, Percentage = 36.41%, Range = 0.4964\n",
            "Qwen BLEU-3 - Avg: 0.3484, Median: 0.0, Highest: 1.0, Lowest: 0, Overall Range: 1.0\n",
            "  Distribution: \n",
            "    <0.3: Count = 121, Percentage = 58.74%, Range = 0.1251\n",
            "    0.3 to <0.5: Count = 14, Percentage = 6.8%, Range = 0.1917\n",
            "    >=0.5: Count = 71, Percentage = 34.47%, Range = 0.4794\n",
            "Qwen BLEU-4 - Avg: 0.3399, Median: 0.0, Highest: 1.0, Lowest: 0, Overall Range: 1.0\n",
            "  Distribution: \n",
            "    <0.3: Count = 123, Percentage = 59.71%, Range = 0.2937\n",
            "    0.3 to <0.5: Count = 13, Percentage = 6.31%, Range = 0.1651\n",
            "    >=0.5: Count = 70, Percentage = 33.98%, Range = 0.4906\n",
            "Qwen-Coder BLEU-1 - Avg: 0.2918, Median: 0.0, Highest: 1.0, Lowest: 0, Overall Range: 1.0\n",
            "  Distribution: \n",
            "    <0.3: Count = 135, Percentage = 65.53%, Range = 0.2591\n",
            "    0.3 to <0.5: Count = 9, Percentage = 4.37%, Range = 0.1386\n",
            "    >=0.5: Count = 62, Percentage = 30.1%, Range = 0.4909\n",
            "Qwen-Coder BLEU-2 - Avg: 0.2845, Median: 0.0, Highest: 1.0, Lowest: 0, Overall Range: 1.0\n",
            "  Distribution: \n",
            "    <0.3: Count = 136, Percentage = 66.02%, Range = 0.2231\n",
            "    0.3 to <0.5: Count = 10, Percentage = 4.85%, Range = 0.1519\n",
            "    >=0.5: Count = 60, Percentage = 29.13%, Range = 0.4955\n",
            "Qwen-Coder BLEU-3 - Avg: 0.28, Median: 0.0, Highest: 1.0, Lowest: 0, Overall Range: 1.0\n",
            "  Distribution: \n",
            "    <0.3: Count = 137, Percentage = 66.5%, Range = 0.2506\n",
            "    0.3 to <0.5: Count = 11, Percentage = 5.34%, Range = 0.1848\n",
            "    >=0.5: Count = 58, Percentage = 28.16%, Range = 0.4853\n",
            "Qwen-Coder BLEU-4 - Avg: 0.2768, Median: 0.0, Highest: 1.0, Lowest: 0, Overall Range: 1.0\n",
            "  Distribution: \n",
            "    <0.3: Count = 139, Percentage = 67.48%, Range = 0.2917\n",
            "    0.3 to <0.5: Count = 10, Percentage = 4.85%, Range = 0.1367\n",
            "    >=0.5: Count = 57, Percentage = 27.67%, Range = 0.4915\n"
          ]
        }
      ],
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "import statistics\n",
        "\n",
        "def calculate_bleu_stats(column_manual, column_model, weights):\n",
        "    scores = [sentence_bleu([column_manual[i]], column_model[i], weights=weights) for i in range(len(column_manual))]\n",
        "\n",
        "    average = round(sum(scores) / len(scores), 4)\n",
        "    median = round(statistics.median(scores), 4)\n",
        "    highest = round(max(scores), 4)\n",
        "    lowest = round(min(scores), 4)\n",
        "    overall_range = round(highest - lowest, 4)\n",
        "\n",
        "    # Categorization\n",
        "    below_03 = [s for s in scores if s < 0.3]\n",
        "    between_03_05 = [s for s in scores if 0.3 <= s < 0.5]\n",
        "    above_05 = [s for s in scores if s >= 0.5]\n",
        "\n",
        "    total = len(scores)\n",
        "\n",
        "    def get_range(category_scores):\n",
        "        return round(max(category_scores) - min(category_scores), 4) if category_scores else 0.0\n",
        "\n",
        "    range_below_03 = get_range(below_03)\n",
        "    range_between_03_05 = get_range(between_03_05)\n",
        "    range_above_05 = get_range(above_05)\n",
        "\n",
        "    return {\n",
        "        \"average\": average,\n",
        "        \"median\": median,\n",
        "        \"highest\": highest,\n",
        "        \"lowest\": lowest,\n",
        "        \"overall_range\": overall_range,\n",
        "        \"scores\": scores,\n",
        "        \"distribution\": {\n",
        "            \"<0.3\": {\n",
        "                \"count\": len(below_03),\n",
        "                \"percentage\": round((len(below_03) / total) * 100, 2),\n",
        "                \"range\": range_below_03\n",
        "            },\n",
        "            \"0.3 to <0.5\": {\n",
        "                \"count\": len(between_03_05),\n",
        "                \"percentage\": round((len(between_03_05) / total) * 100, 2),\n",
        "                \"range\": range_between_03_05\n",
        "            },\n",
        "            \">=0.5\": {\n",
        "                \"count\": len(above_05),\n",
        "                \"percentage\": round((len(above_05) / total) * 100, 2),\n",
        "                \"range\": range_above_05\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "def compute_bleu_scores(column_manual, column_llama, column_qwen, column_qwen_coder):\n",
        "    models = {\n",
        "        \"Llama\": column_llama,\n",
        "        \"Qwen\": column_qwen,\n",
        "        \"Qwen-Coder\": column_qwen_coder\n",
        "    }\n",
        "    weights_list = {\n",
        "        \"BLEU-1\": (1.0, 0, 0, 0),\n",
        "        \"BLEU-2\": (0.5, 0.5),\n",
        "        \"BLEU-3\": (0.33, 0.33, 0.33),\n",
        "        \"BLEU-4\": (0.25, 0.25, 0.25, 0.25)\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "    for model_name, column_model in models.items():\n",
        "        results[model_name] = {}\n",
        "        for bleu_name, weights in weights_list.items():\n",
        "            stats = calculate_bleu_stats(column_manual, column_model, weights)\n",
        "            results[model_name][bleu_name] = stats\n",
        "\n",
        "            print(f\"{model_name} {bleu_name} - Avg: {stats['average']}, Median: {stats['median']}, \"\n",
        "                  f\"Highest: {stats['highest']}, Lowest: {stats['lowest']}, Overall Range: {stats['overall_range']}\")\n",
        "            print(f\"  Distribution: \")\n",
        "            for category, data in stats[\"distribution\"].items():\n",
        "                print(f\"    {category}: Count = {data['count']}, Percentage = {data['percentage']}%, Range = {data['range']}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# Compute BLEU scores\n",
        "results = compute_bleu_scores(column_manual, column_llama, column_qwen, column_qwen_coder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2STqhQw-InB",
        "outputId": "4a32e315-ae93-466f-ef1b-4bfc74b08eae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "## Low BLEU-2 Scores (<0.3)\n",
            "98\n",
            "Average  manual : 3.8877551020408165\n",
            "Median  manual : 0.0\n",
            "Average  llama : 36.03061224489796\n",
            "Median  llama : 4.5\n",
            "Average  qwen : 15.60204081632653\n",
            "Median  qwen : 0.0\n",
            "Average  qwen_coder : 10.60204081632653\n",
            "Median  qwen_coder : 0.0\n",
            "-----------------------------------------------------\n",
            "## High BLEU-2 Scores (>0.5)\n",
            "49\n",
            "Average  manual : 11.877551020408163\n",
            "Median  manual : 9\n",
            "Average  llama : 13.306122448979592\n",
            "Median  llama : 10\n",
            "Average  qwen : 12.489795918367347\n",
            "Median  qwen : 9\n",
            "Average  qwen_coder : 12.244897959183673\n",
            "Median  qwen_coder : 10\n",
            "\n",
            "#######################################################\n",
            "\n",
            "## Low BLEU-4 Scores (<0.3)\n",
            "102\n",
            "Average  manual : 4.147058823529412\n",
            "Median  manual : 0.0\n",
            "Average  llama : 35.833333333333336\n",
            "Median  llama : 5.0\n",
            "Average  qwen : 15.872549019607844\n",
            "Median  qwen : 0.0\n",
            "Average  qwen_coder : 10.264705882352942\n",
            "Median  qwen_coder : 0.0\n",
            "-----------------------------------------------------\n",
            "## High BLEU-4 Scores (>0.5)\n",
            "46\n",
            "Average  manual : 11.826086956521738\n",
            "Median  manual : 8.5\n",
            "Average  llama : 13.0\n",
            "Median  llama : 10.0\n",
            "Average  qwen : 12.521739130434783\n",
            "Median  qwen : 8.5\n",
            "Average  qwen_coder : 12.282608695652174\n",
            "Median  qwen_coder : 9.5\n"
          ]
        }
      ],
      "source": [
        "def calculate_bleu_stats(bleu, llama_bleu_scores, qwen_bleu_scores, qwen_coder_bleu_scores, column_manual, column_llama, column_qwen, column_qwen_coder):\n",
        "    def calculate_filtered_stats(condition):\n",
        "        filtered_word_counts = {\"manual\": [], \"llama\": [], \"qwen\": [], \"qwen_coder\": []}\n",
        "\n",
        "        for i in range(len(llama_bleu_scores)):\n",
        "            if condition(llama_bleu_scores[i], qwen_bleu_scores[i], qwen_coder_bleu_scores[i]):\n",
        "                filtered_word_counts[\"manual\"].append(len(column_manual[i].split()))\n",
        "                filtered_word_counts[\"llama\"].append(len(column_llama[i].split()))\n",
        "                filtered_word_counts[\"qwen\"].append(len(column_qwen[i].split()))\n",
        "                filtered_word_counts[\"qwen_coder\"].append(len(column_qwen_coder[i].split()))\n",
        "\n",
        "        count = len(filtered_word_counts[\"manual\"])\n",
        "        if count == 0:\n",
        "            print(\"No matching entries found.\")\n",
        "            return\n",
        "\n",
        "        print(count)\n",
        "        for key in filtered_word_counts:\n",
        "            print(\"Average \", key, \":\", sum(filtered_word_counts[key]) / count)\n",
        "            print(\"Median \", key, \":\", statistics.median(filtered_word_counts[key]))\n",
        "\n",
        "    print(f\"## Low BLEU-{bleu} Scores (<0.3)\")\n",
        "    calculate_filtered_stats(lambda l, q, qc: l < 0.3 and q < 0.3 and qc < 0.3)\n",
        "\n",
        "    print(\"-----------------------------------------------------\")\n",
        "\n",
        "    print(f\"## High BLEU-{bleu} Scores (>0.5)\")\n",
        "    calculate_filtered_stats(lambda l, q, qc: l > 0.5 and q > 0.5 and qc > 0.5)\n",
        "\n",
        "\n",
        "calculate_bleu_stats(2, results['Llama']['BLEU-2']['scores'], results['Qwen']['BLEU-2']['scores'], results['Qwen-Coder']['BLEU-2']['scores'], column_manual, column_llama, column_qwen, column_qwen_coder)\n",
        "\n",
        "print(\"\\n#######################################################\\n\")\n",
        "\n",
        "calculate_bleu_stats(4, results['Llama']['BLEU-4']['scores'], results['Qwen']['BLEU-4']['scores'], results['Qwen-Coder']['BLEU-4']['scores'], column_manual, column_llama, column_qwen, column_qwen_coder)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
