{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZFszMCv-Im6",
        "outputId": "d1c1c2bf-a2db-4a32-bce5-5ba23f18f420"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import csv\n",
        "import nltk\n",
        "import statistics\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from nltk.translate.bleu_score import sentence_bleu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fAkplXJN-Im8"
      },
      "outputs": [],
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = PorterStemmer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "\n",
        "def text_cleaning(text: str) -> str:\n",
        "    text = str(text)\n",
        "\n",
        "    text = text.encode(\"ascii\", \"ignore\").decode()\n",
        "\n",
        "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip().lower()\n",
        "\n",
        "    # Tokenization\n",
        "    words = nltk.word_tokenize(text)\n",
        "\n",
        "    # POS tagging and Lemmatization\n",
        "    pos_tags = nltk.pos_tag(words)\n",
        "    pos_map = {'N': wordnet.NOUN, 'V': wordnet.VERB, 'R': wordnet.ADV, 'J': wordnet.ADJ}\n",
        "    lemmatized_words = [lemmatizer.lemmatize(word, pos_map.get(pos[0], wordnet.NOUN)) for word, pos in pos_tags]\n",
        "\n",
        "    # Stemming\n",
        "    stemmed_words = [stemmer.stem(word) for word in lemmatized_words]\n",
        "\n",
        "    return ' '.join(stemmed_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GDMVl6nr-Im9"
      },
      "outputs": [],
      "source": [
        "column_manual = []\n",
        "column_llama = []\n",
        "column_qwen = []\n",
        "column_qwen_coder = []\n",
        "\n",
        "\n",
        "with open('input-v1.csv', 'r', encoding='utf-8') as csv_file:\n",
        "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "    next(csv_reader)\n",
        "    idx = 0\n",
        "    for row in csv_reader:\n",
        "        column_manual.append(text_cleaning(row[1]))\n",
        "        column_llama.append(text_cleaning(row[2]))\n",
        "        column_qwen.append(text_cleaning(row[3]))\n",
        "        column_qwen_coder.append(text_cleaning(row[4]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DbUmgYp-Im9",
        "outputId": "34dd183d-8953-4878-d931-e748d012232a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Manual\n",
            "Average: 10.027027027027026\n",
            "Median: 6\n"
          ]
        }
      ],
      "source": [
        "word_counts = [len(sentence.split()) for sentence in column_manual]\n",
        "\n",
        "average = sum(word_counts) / len(column_manual)\n",
        "median = statistics.median(word_counts)\n",
        "\n",
        "print(\"Manual\")\n",
        "print(\"Average:\", average)\n",
        "print(\"Median:\", median)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8DfB6Ku-Im-",
        "outputId": "7182f424-fc86-4a29-f969-e8c0a10fabc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Llama\n",
            "Average: 25.535135135135135\n",
            "Median: 7\n"
          ]
        }
      ],
      "source": [
        "word_counts = [len(sentence.split()) for sentence in column_llama]\n",
        "\n",
        "average = sum(word_counts) / len(column_llama)\n",
        "median = statistics.median(word_counts)\n",
        "\n",
        "print(\"Llama\")\n",
        "print(\"Average:\", average)\n",
        "print(\"Median:\", median)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ydn3rNDO-Im-",
        "outputId": "bbc16a44-7ada-4087-9506-395f1d00ab7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Qwen\n",
            "Average: 14.416216216216217\n",
            "Median: 2\n"
          ]
        }
      ],
      "source": [
        "word_counts = [len(sentence.split()) for sentence in column_qwen]\n",
        "\n",
        "average = sum(word_counts) / len(column_qwen)\n",
        "median = statistics.median(word_counts)\n",
        "\n",
        "print(\"Qwen\")\n",
        "print(\"Average:\", average)\n",
        "print(\"Median:\", median)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDcs2UUa-Im-",
        "outputId": "f2d9eef2-517b-420d-d2a3-7b47191b74ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Qwen-Coder\n",
            "Average: 9.92972972972973\n",
            "Median: 2\n"
          ]
        }
      ],
      "source": [
        "word_counts = [len(sentence.split()) for sentence in column_qwen_coder]\n",
        "\n",
        "average = sum(word_counts) / len(column_qwen_coder)\n",
        "median = statistics.median(word_counts)\n",
        "\n",
        "print(\"Qwen-Coder\")\n",
        "print(\"Average:\", average)\n",
        "print(\"Median:\", median)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wA42nlvV-Im-",
        "outputId": "57389a48-8645-4330-b4a5-2fd28575a50a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average BLEU-1 score: 0.5756445016525995\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ],
      "source": [
        "# Llama-1\n",
        "llama_scores = []\n",
        "scores = []\n",
        "for i in range(len(column_manual)):\n",
        "    score = sentence_bleu([column_manual[i]], column_llama[i], weights=(1.0, 0, 0, 0))\n",
        "    scores.append(score)\n",
        "\n",
        "avg_score = sum(scores) / len(scores)\n",
        "llama_scores.append(avg_score)\n",
        "print(f\"Average BLEU-1 score: {avg_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrv0QqOX-Im_",
        "outputId": "85b19cbc-2804-495c-95ae-95c347675989"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average BLEU-2 score: 0.5442376369669014\n"
          ]
        }
      ],
      "source": [
        "# Llama-2\n",
        "scores = []\n",
        "for i in range(len(column_manual)):\n",
        "    score = sentence_bleu([column_manual[i]], column_llama[i], weights=(0.5, 0.5))\n",
        "    scores.append(score)\n",
        "\n",
        "llama_bleu_2_scores = scores\n",
        "\n",
        "# Calculate the average BLEU score for the columns\n",
        "avg_score = sum(scores) / len(scores)\n",
        "llama_scores.append(avg_score)\n",
        "print(f\"Average BLEU-2 score: {avg_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fp2gshK-Im_",
        "outputId": "394034f2-e0cd-4bba-e9d7-e0317d4ddfa3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average BLEU-3 score: 0.5301353680021367\n"
          ]
        }
      ],
      "source": [
        "# Llama-3\n",
        "scores = []\n",
        "for i in range(len(column_manual)):\n",
        "    score = sentence_bleu([column_manual[i]], column_llama[i], weights=(0.33, 0.33, 0.33))\n",
        "    scores.append(score)\n",
        "\n",
        "# Calculate the average BLEU score for the columns\n",
        "avg_score = sum(scores) / len(scores)\n",
        "llama_scores.append(avg_score)\n",
        "print(f\"Average BLEU-3 score: {avg_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZhWeLfR-Im_",
        "outputId": "c61f4968-7001-4fb0-84a6-57c0179b5a2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average BLEU-4 score: 0.5150906158232708\n"
          ]
        }
      ],
      "source": [
        "# Llama-4\n",
        "scores = []\n",
        "for i in range(len(column_manual)):\n",
        "    score = sentence_bleu([column_manual[i]], column_llama[i], weights=(0.25, 0.25, 0.25, 0.25))\n",
        "    scores.append(score)\n",
        "\n",
        "llama_bleu_4_scores = scores\n",
        "\n",
        "# Calculate the average BLEU score for the columns\n",
        "avg_score = sum(scores) / len(scores)\n",
        "llama_scores.append(avg_score)\n",
        "print(f\"Average BLEU-4 score: {avg_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FhFdCSW-InA",
        "outputId": "6473e46f-2c2e-4516-f723-170eb0836a0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average BLEU-1 score: 0.5720368504807458\n"
          ]
        }
      ],
      "source": [
        "# Qwen-1\n",
        "scores = []\n",
        "qwen_scores = []\n",
        "for i in range(len(column_manual)):\n",
        "    score = sentence_bleu([column_manual[i]], column_qwen[i], weights=(1.0, 0, 0, 0))\n",
        "    scores.append(score)\n",
        "\n",
        "# Calculate the average BLEU score for the columns\n",
        "avg_score = sum(scores) / len(scores)\n",
        "qwen_scores.append(avg_score)\n",
        "print(f\"Average BLEU-1 score: {avg_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QioktiSz-InA",
        "outputId": "ec07a60d-38a8-468f-9cf9-65a4ec49cfcb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average BLEU-2 score: 0.5328367089636845\n"
          ]
        }
      ],
      "source": [
        "# Qwen-2\n",
        "scores = []\n",
        "for i in range(len(column_manual)):\n",
        "    score = sentence_bleu([column_manual[i]], column_qwen[i], weights=(0.5, 0.5))\n",
        "    scores.append(score)\n",
        "\n",
        "qwen_bleu_2_scores = scores\n",
        "\n",
        "# Calculate the average BLEU score for the columns\n",
        "avg_score = sum(scores) / len(scores)\n",
        "qwen_scores.append(avg_score)\n",
        "print(f\"Average BLEU-2 score: {avg_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1S-rzSV-InA",
        "outputId": "8a5f825f-4080-4c0d-e314-c04bd28e18de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average BLEU-3 score: 0.5245553580266875\n"
          ]
        }
      ],
      "source": [
        "# Qwen-3\n",
        "scores = []\n",
        "for i in range(len(column_manual)):\n",
        "    score = sentence_bleu([column_manual[i]], column_qwen[i], weights=(0.33, 0.33, 0.33))\n",
        "    scores.append(score)\n",
        "\n",
        "# Calculate the average BLEU score for the columns\n",
        "avg_score = sum(scores) / len(scores)\n",
        "qwen_scores.append(avg_score)\n",
        "print(f\"Average BLEU-3 score: {avg_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMX7cdEp-InA",
        "outputId": "f8f92b34-cc98-446a-f5a6-0a93883b08ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average BLEU-4 score: 0.5150390987531424\n"
          ]
        }
      ],
      "source": [
        "# Qwen-4\n",
        "scores = []\n",
        "for i in range(len(column_manual)):\n",
        "    score = sentence_bleu([column_manual[i]], column_qwen[i], weights=(0.25, 0.25, 0.25, 0.25))\n",
        "    scores.append(score)\n",
        "\n",
        "qwen_bleu_4_scores = scores\n",
        "\n",
        "# Calculate the average BLEU score for the columns\n",
        "avg_score = sum(scores) / len(scores)\n",
        "qwen_scores.append(avg_score)\n",
        "print(f\"Average BLEU-4 score: {avg_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiGQsWg5-InB",
        "outputId": "5aa61ede-402a-40ea-e30b-87b8b137e27d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average BLEU-1 score: 0.5307959497576407\n"
          ]
        }
      ],
      "source": [
        "# Qwen-Coder-1\n",
        "qwen_coder_scores = []\n",
        "scores = []\n",
        "for i in range(len(column_manual)):\n",
        "    score = sentence_bleu([column_manual[i]], column_qwen_coder[i], weights=(1.0, 0, 0, 0))\n",
        "    scores.append(score)\n",
        "\n",
        "# Calculate the average BLEU score for the columns\n",
        "avg_score = sum(scores) / len(scores)\n",
        "qwen_coder_scores.append(avg_score)\n",
        "print(f\"Average BLEU-1 score: {avg_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2-e-Rdw-InB",
        "outputId": "f7a1fb17-8170-44cb-8c72-adb1266f2def"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average BLEU-2 score: 0.48019649561426325\n"
          ]
        }
      ],
      "source": [
        "# Qwen-Coder-2\n",
        "scores = []\n",
        "for i in range(len(column_manual)):\n",
        "    score = sentence_bleu([column_manual[i]], column_qwen_coder[i], weights=(0.5, 0.5))\n",
        "    scores.append(score)\n",
        "\n",
        "qwen_coder_bleu_2_scores = scores\n",
        "\n",
        "# Calculate the average BLEU score for the columns\n",
        "avg_score = sum(scores) / len(scores)\n",
        "qwen_coder_scores.append(avg_score)\n",
        "print(f\"Average BLEU-2 score: {avg_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXGSJMjE-InB",
        "outputId": "8c62edd8-3833-42eb-d29d-32a88f90e222"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average BLEU-3 score: 0.47120493426960197\n"
          ]
        }
      ],
      "source": [
        "# Qwen-Coder-3\n",
        "scores = []\n",
        "for i in range(len(column_manual)):\n",
        "    score = sentence_bleu([column_manual[i]], column_qwen_coder[i], weights=(0.33, 0.33, 0.33))\n",
        "    scores.append(score)\n",
        "\n",
        "# Calculate the average BLEU score for the columns\n",
        "avg_score = sum(scores) / len(scores)\n",
        "qwen_coder_scores.append(avg_score)\n",
        "print(f\"Average BLEU-3 score: {avg_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oA-xGegC-InB",
        "outputId": "9b96f45e-f261-4c5f-8ef4-10c0fd5ad7c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average BLEU-4 score: 0.46743096162078096\n"
          ]
        }
      ],
      "source": [
        "# Qwen-Coder-4\n",
        "scores = []\n",
        "for i in range(len(column_manual)):\n",
        "    score = sentence_bleu([column_manual[i]], column_qwen_coder[i], weights=(0.25, 0.25, 0.25, 0.25))\n",
        "    scores.append(score)\n",
        "\n",
        "qwen_coder_bleu_4_scores = scores\n",
        "\n",
        "# Calculate the average BLEU score for the columns\n",
        "avg_score = sum(scores) / len(scores)\n",
        "qwen_coder_scores.append(avg_score)\n",
        "print(f\"Average BLEU-4 score: {avg_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noH6jFTj-InB",
        "outputId": "ff1912aa-82bb-4730-b9fb-144a6c40057e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.5756445016525995, 0.5442376369669014, 0.5301353680021367, 0.5150906158232708]\n",
            "[0.5720368504807458, 0.5328367089636845, 0.5245553580266875, 0.5150390987531424]\n",
            "[0.5307959497576407, 0.48019649561426325, 0.47120493426960197, 0.46743096162078096]\n"
          ]
        }
      ],
      "source": [
        "print(llama_scores)\n",
        "print(qwen_scores)\n",
        "print(qwen_coder_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2STqhQw-InB",
        "outputId": "520d81f3-f36b-48eb-bf3d-807fbac2d64e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "## Low BLEU-2 Scores (<0.3)\n",
            "52\n",
            "Average  manual : 12.134615384615385\n",
            "Median  manual : 10.5\n",
            "Average  llama : 52.84615384615385\n",
            "Median  llama : 8.0\n",
            "Average  qwen : 23.03846153846154\n",
            "Median  qwen : 2.0\n",
            "Average  qwen_coder : 17.576923076923077\n",
            "Median  qwen_coder : 2.0\n",
            "-----------------------------------------------------\n",
            "## High BLEU-2 Scores (>0.5)\n",
            "72\n",
            "Average  manual : 6.736111111111111\n",
            "Median  manual : 2.0\n",
            "Average  llama : 7.541666666666667\n",
            "Median  llama : 2.0\n",
            "Average  qwen : 7.25\n",
            "Median  qwen : 2.0\n",
            "Average  qwen_coder : 7.027777777777778\n",
            "Median  qwen_coder : 2.0\n",
            "\n",
            "#######################################################\n",
            "\n",
            "## Low BLEU-4 Scores (<0.3)\n",
            "58\n",
            "Average  manual : 12.241379310344827\n",
            "Median  manual : 10.5\n",
            "Average  llama : 50.293103448275865\n",
            "Median  llama : 10.5\n",
            "Average  qwen : 22.948275862068964\n",
            "Median  qwen : 2.0\n",
            "Average  qwen_coder : 16.689655172413794\n",
            "Median  qwen_coder : 2.0\n",
            "-----------------------------------------------------\n",
            "## High BLEU-4 Scores (>0.5)\n",
            "70\n",
            "Average  manual : 6.671428571428572\n",
            "Median  manual : 2.0\n",
            "Average  llama : 7.328571428571428\n",
            "Median  llama : 2.0\n",
            "Average  qwen : 7.1571428571428575\n",
            "Median  qwen : 2.0\n",
            "Average  qwen_coder : 6.942857142857143\n",
            "Median  qwen_coder : 2.0\n"
          ]
        }
      ],
      "source": [
        "def calculate_bleu_stats(bleu, llama_bleu_scores, qwen_bleu_scores, qwen_coder_bleu_scores, column_manual, column_llama, column_qwen, column_qwen_coder):\n",
        "    def calculate_filtered_stats(condition):\n",
        "        filtered_word_counts = {\"manual\": [], \"llama\": [], \"qwen\": [], \"qwen_coder\": []}\n",
        "\n",
        "        for i in range(len(llama_bleu_scores)):\n",
        "            if condition(llama_bleu_scores[i], qwen_bleu_scores[i], qwen_coder_bleu_scores[i]):\n",
        "                filtered_word_counts[\"manual\"].append(len(column_manual[i].split()))\n",
        "                filtered_word_counts[\"llama\"].append(len(column_llama[i].split()))\n",
        "                filtered_word_counts[\"qwen\"].append(len(column_qwen[i].split()))\n",
        "                filtered_word_counts[\"qwen_coder\"].append(len(column_qwen_coder[i].split()))\n",
        "\n",
        "        count = len(filtered_word_counts[\"manual\"])\n",
        "        if count == 0:\n",
        "            print(\"No matching entries found.\")\n",
        "            return\n",
        "\n",
        "        print(count)\n",
        "        for key in filtered_word_counts:\n",
        "            print(\"Average \", key, \":\", sum(filtered_word_counts[key]) / count)\n",
        "            print(\"Median \", key, \":\", statistics.median(filtered_word_counts[key]))\n",
        "\n",
        "    print(f\"## Low BLEU-{bleu} Scores (<0.3)\")\n",
        "    calculate_filtered_stats(lambda l, q, qc: l < 0.3 and q < 0.3 and qc < 0.3)\n",
        "\n",
        "    print(\"-----------------------------------------------------\")\n",
        "\n",
        "    print(f\"## High BLEU-{bleu} Scores (>0.5)\")\n",
        "    calculate_filtered_stats(lambda l, q, qc: l > 0.5 and q > 0.5 and qc > 0.5)\n",
        "\n",
        "\n",
        "calculate_bleu_stats(2, llama_bleu_2_scores, qwen_bleu_2_scores, qwen_coder_bleu_2_scores, column_manual, column_llama, column_qwen, column_qwen_coder)\n",
        "\n",
        "print(\"\\n#######################################################\\n\")\n",
        "\n",
        "calculate_bleu_stats(4, llama_bleu_4_scores, qwen_bleu_4_scores, qwen_coder_bleu_4_scores, column_manual, column_llama, column_qwen, column_qwen_coder)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
