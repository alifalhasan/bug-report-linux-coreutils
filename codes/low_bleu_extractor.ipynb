{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1KmY_MlIG17",
        "outputId": "aaad1399-a454-4660-fa11-20dd7eacd699"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/drive/MyDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZFszMCv-Im6",
        "outputId": "0e9bdd66-ad13-459f-e3f2-53bb9df202fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import csv\n",
        "import nltk\n",
        "import statistics\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from nltk.translate.bleu_score import sentence_bleu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fAkplXJN-Im8"
      },
      "outputs": [],
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = PorterStemmer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "\n",
        "def text_cleaning(text: str) -> str:\n",
        "    text = str(text)\n",
        "\n",
        "    text = text.encode(\"ascii\", \"ignore\").decode()\n",
        "\n",
        "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip().lower()\n",
        "\n",
        "    # Tokenization\n",
        "    words = nltk.word_tokenize(text)\n",
        "\n",
        "    # POS tagging and Lemmatization\n",
        "    pos_tags = nltk.pos_tag(words)\n",
        "    pos_map = {'N': wordnet.NOUN, 'V': wordnet.VERB, 'R': wordnet.ADV, 'J': wordnet.ADJ}\n",
        "    lemmatized_words = [lemmatizer.lemmatize(word, pos_map.get(pos[0], wordnet.NOUN)) for word, pos in pos_tags]\n",
        "\n",
        "    # Stemming\n",
        "    stemmed_words = [stemmer.stem(word) for word in lemmatized_words]\n",
        "\n",
        "    return ' '.join(stemmed_words)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_ids = []\n",
        "column_manual = []\n",
        "column_llama = []\n",
        "column_qwen = []\n",
        "column_qwen_coder = []\n",
        "descriptions = {}\n",
        "manual = {}\n",
        "llama = {}\n",
        "\n",
        "with open('descriptions.csv', 'r', encoding='utf-8') as desc_file:\n",
        "    desc_reader = csv.reader(desc_file, delimiter=',')\n",
        "    next(desc_reader)\n",
        "    for row in desc_reader:\n",
        "        descriptions[row[0]] = row[1]\n",
        "\n",
        "with open('input-v1.csv', 'r', encoding='utf-8') as csv_file:\n",
        "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "    next(csv_reader)\n",
        "    for row in csv_reader:\n",
        "        data_ids.append(row[0])\n",
        "        manual[row[0]] = row[1]\n",
        "        llama[row[0]] = row[2]\n",
        "        column_manual.append(text_cleaning(row[1]))\n",
        "        column_llama.append(text_cleaning(row[2]))\n",
        "        column_qwen.append(text_cleaning(row[3]))\n",
        "        column_qwen_coder.append(text_cleaning(row[4]))\n",
        "\n",
        "def calculate_bleu_stats(column_manual, column_model, weights):\n",
        "    scores = []\n",
        "    for i in range(len(column_manual)):\n",
        "        if not column_manual[i] and not column_model[i]:\n",
        "            scores.append(1.0)\n",
        "        else:\n",
        "            scores.append(sentence_bleu([column_manual[i]], column_model[i], weights=weights))\n",
        "\n",
        "    average = round(sum(scores) / len(scores), 4)\n",
        "    median = round(statistics.median(scores), 4)\n",
        "    highest = round(max(scores), 4)\n",
        "    lowest = round(min(scores), 4)\n",
        "    overall_range = round(highest - lowest, 4)\n",
        "\n",
        "    below_03 = [s for s in scores if s < 0.3]\n",
        "    between_03_05 = [s for s in scores if 0.3 <= s < 0.5]\n",
        "    above_05 = [s for s in scores if s >= 0.5]\n",
        "    total = len(scores)\n",
        "\n",
        "    def get_range(category_scores):\n",
        "        return round(max(category_scores) - min(category_scores), 4) if category_scores else 0.0\n",
        "\n",
        "    distribution = {\n",
        "        \"<0.3\": {\"count\": len(below_03), \"percentage\": round((len(below_03) / total) * 100, 2), \"range\": get_range(below_03)},\n",
        "        \"0.3 to <0.5\": {\"count\": len(between_03_05), \"percentage\": round((len(between_03_05) / total) * 100, 2), \"range\": get_range(between_03_05)},\n",
        "        \">=0.5\": {\"count\": len(above_05), \"percentage\": round((len(above_05) / total) * 100, 2), \"range\": get_range(above_05)}\n",
        "    }\n",
        "\n",
        "    print(\"Distribution:\")\n",
        "    for category, data in distribution.items():\n",
        "        print(f\"  {category}: Count = {data['count']}, Percentage = {data['percentage']}%, Range = {data['range']}\")\n",
        "\n",
        "    return {\n",
        "        \"average\": average,\n",
        "        \"median\": median,\n",
        "        \"highest\": highest,\n",
        "        \"lowest\": lowest,\n",
        "        \"overall_range\": overall_range,\n",
        "        \"scores\": scores,\n",
        "        \"distribution\": distribution\n",
        "    }\n",
        "\n",
        "def compute_bleu_scores(column_manual, column_llama, column_qwen, column_qwen_coder):\n",
        "    models = {\"Llama\": column_llama, \"Qwen\": column_qwen, \"Qwen-Coder\": column_qwen_coder}\n",
        "    weights_list = {\"BLEU-1\": (1.0, 0, 0, 0), \"BLEU-2\": (0.5, 0.5), \"BLEU-3\": (0.33, 0.33, 0.33), \"BLEU-4\": (0.25, 0.25, 0.25, 0.25)}\n",
        "\n",
        "    results = {}\n",
        "    for model_name, column_model in models.items():\n",
        "        results[model_name] = {}\n",
        "        for bleu_name, weights in weights_list.items():\n",
        "            stats = calculate_bleu_stats(column_manual, column_model, weights)\n",
        "            results[model_name][bleu_name] = stats\n",
        "            print(f\"{model_name} {bleu_name} - Avg: {stats['average']}, Median: {stats['median']}, Highest: {stats['highest']}, Lowest: {stats['lowest']}, Overall Range: {stats['overall_range']}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "results = compute_bleu_scores(column_manual, column_llama, column_qwen, column_qwen_coder)\n",
        "\n",
        "def get_low_bleu_ids(threshold=0.3):\n",
        "    low_bleu_ids = [data_ids[i] for i in range(len(data_ids)) if all(results[model]['BLEU-2']['scores'][i] < threshold for model in results)]\n",
        "    return low_bleu_ids\n",
        "\n",
        "low_bleu_ids = get_low_bleu_ids()\n",
        "print(f\"Number of IDs with low BLEU scores: {len(low_bleu_ids)}\")\n",
        "print(\"Low BLEU IDs:\", low_bleu_ids)\n",
        "\n",
        "with open('low_bleu_data_updated.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
        "    csv_writer = csv.writer(csvfile)\n",
        "    csv_writer.writerow([\"ID\", \"Description\", \"Manual\", \"Llama\"])\n",
        "    for id in low_bleu_ids:\n",
        "        csv_writer.writerow([id, descriptions.get(id, \"\"), manual.get(id, \"\"), llama.get(id, \"\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQwS9xSUTgzH",
        "outputId": "1ccf0d5e-6a2a-41a7-bf12-7e78b072f472"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution:\n",
            "  <0.3: Count = 74, Percentage = 35.92%, Range = 0.2989\n",
            "  0.3 to <0.5: Count = 14, Percentage = 6.8%, Range = 0.1617\n",
            "  >=0.5: Count = 118, Percentage = 57.28%, Range = 0.5\n",
            "Llama BLEU-1 - Avg: 0.5742, Median: 0.6943, Highest: 1.0, Lowest: 0, Overall Range: 1.0\n",
            "Distribution:\n",
            "  <0.3: Count = 76, Percentage = 36.89%, Range = 0.2673\n",
            "  0.3 to <0.5: Count = 16, Percentage = 7.77%, Range = 0.1603\n",
            "  >=0.5: Count = 114, Percentage = 55.34%, Range = 0.4951\n",
            "Llama BLEU-2 - Avg: 0.5585, Median: 0.6601, Highest: 1.0, Lowest: 0, Overall Range: 1.0\n",
            "Distribution:\n",
            "  <0.3: Count = 77, Percentage = 37.38%, Range = 0.2789\n",
            "  0.3 to <0.5: Count = 19, Percentage = 9.22%, Range = 0.1945\n",
            "  >=0.5: Count = 110, Percentage = 53.4%, Range = 0.4967\n",
            "Llama BLEU-3 - Avg: 0.5517, Median: 0.65, Highest: 1.0, Lowest: 0, Overall Range: 1.0\n",
            "Distribution:\n",
            "  <0.3: Count = 80, Percentage = 38.83%, Range = 0.298\n",
            "  0.3 to <0.5: Count = 20, Percentage = 9.71%, Range = 0.1918\n",
            "  >=0.5: Count = 106, Percentage = 51.46%, Range = 0.4846\n",
            "Llama BLEU-4 - Avg: 0.5396, Median: 0.5847, Highest: 1.0, Lowest: 0, Overall Range: 1.0\n",
            "Distribution:\n",
            "  <0.3: Count = 65, Percentage = 31.55%, Range = 0.2927\n",
            "  0.3 to <0.5: Count = 11, Percentage = 5.34%, Range = 0.1682\n",
            "  >=0.5: Count = 130, Percentage = 63.11%, Range = 0.4928\n",
            "Qwen BLEU-1 - Avg: 0.6238, Median: 0.9537, Highest: 1.0, Lowest: 0, Overall Range: 1.0\n",
            "Distribution:\n",
            "  <0.3: Count = 66, Percentage = 32.04%, Range = 0.2082\n",
            "  0.3 to <0.5: Count = 11, Percentage = 5.34%, Range = 0.1669\n",
            "  >=0.5: Count = 129, Percentage = 62.62%, Range = 0.4964\n",
            "Qwen BLEU-2 - Avg: 0.6156, Median: 0.9535, Highest: 1.0, Lowest: 0, Overall Range: 1.0\n",
            "Distribution:\n",
            "  <0.3: Count = 66, Percentage = 32.04%, Range = 0.1726\n",
            "  0.3 to <0.5: Count = 15, Percentage = 7.28%, Range = 0.1917\n",
            "  >=0.5: Count = 125, Percentage = 60.68%, Range = 0.4794\n",
            "Qwen BLEU-3 - Avg: 0.6099, Median: 0.943, Highest: 1.0, Lowest: 0, Overall Range: 1.0\n",
            "Distribution:\n",
            "  <0.3: Count = 69, Percentage = 33.5%, Range = 0.2937\n",
            "  0.3 to <0.5: Count = 13, Percentage = 6.31%, Range = 0.1651\n",
            "  >=0.5: Count = 124, Percentage = 60.19%, Range = 0.4906\n",
            "Qwen BLEU-4 - Avg: 0.6009, Median: 0.8982, Highest: 1.0, Lowest: 0, Overall Range: 1.0\n",
            "Distribution:\n",
            "  <0.3: Count = 78, Percentage = 37.86%, Range = 0.2591\n",
            "  0.3 to <0.5: Count = 9, Percentage = 4.37%, Range = 0.1386\n",
            "  >=0.5: Count = 119, Percentage = 57.77%, Range = 0.4909\n",
            "Qwen-Coder BLEU-1 - Avg: 0.5616, Median: 0.7345, Highest: 1.0, Lowest: 0, Overall Range: 1.0\n",
            "Distribution:\n",
            "  <0.3: Count = 79, Percentage = 38.35%, Range = 0.2231\n",
            "  0.3 to <0.5: Count = 10, Percentage = 4.85%, Range = 0.1519\n",
            "  >=0.5: Count = 117, Percentage = 56.8%, Range = 0.4955\n",
            "Qwen-Coder BLEU-2 - Avg: 0.5539, Median: 0.7134, Highest: 1.0, Lowest: 0, Overall Range: 1.0\n",
            "Distribution:\n",
            "  <0.3: Count = 80, Percentage = 38.83%, Range = 0.2506\n",
            "  0.3 to <0.5: Count = 11, Percentage = 5.34%, Range = 0.1848\n",
            "  >=0.5: Count = 115, Percentage = 55.83%, Range = 0.4853\n",
            "Qwen-Coder BLEU-3 - Avg: 0.5491, Median: 0.7119, Highest: 1.0, Lowest: 0, Overall Range: 1.0\n",
            "Distribution:\n",
            "  <0.3: Count = 82, Percentage = 39.81%, Range = 0.2917\n",
            "  0.3 to <0.5: Count = 11, Percentage = 5.34%, Range = 0.1496\n",
            "  >=0.5: Count = 113, Percentage = 54.85%, Range = 0.4915\n",
            "Qwen-Coder BLEU-4 - Avg: 0.5456, Median: 0.6978, Highest: 1.0, Lowest: 0, Overall Range: 1.0\n",
            "Number of IDs with low BLEU scores: 38\n",
            "Low BLEU IDs: ['1121021', '2236321', '2208048', '1646701', '2162873', '2124510', '1960792', '1944688', '1877625', '1800597', '1705229', '1674156', '199066', '1637531', '1611211', '1303456', '1555079', '1470769', '1024730', '1446494', '1361694', '1001092', '1376801', '1347746', '1349701', '1285623', '1303795', '440056', '981845', '706605', '1249695', '1196642', '1270480', '920806', '1235873', '239501', '284881', '251800']\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}