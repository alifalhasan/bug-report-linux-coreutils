{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZFszMCv-Im6",
        "outputId": "0e9bdd66-ad13-459f-e3f2-53bb9df202fd"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import csv\n",
        "import nltk\n",
        "import statistics\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from nltk.translate.bleu_score import sentence_bleu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAkplXJN-Im8"
      },
      "outputs": [],
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = PorterStemmer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "\n",
        "def text_cleaning(text: str) -> str:\n",
        "    text = str(text)\n",
        "\n",
        "    text = text.encode(\"ascii\", \"ignore\").decode()\n",
        "\n",
        "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip().lower()\n",
        "\n",
        "    # Tokenization\n",
        "    words = nltk.word_tokenize(text)\n",
        "\n",
        "    # POS tagging and Lemmatization\n",
        "    pos_tags = nltk.pos_tag(words)\n",
        "    pos_map = {'N': wordnet.NOUN, 'V': wordnet.VERB, 'R': wordnet.ADV, 'J': wordnet.ADJ}\n",
        "    lemmatized_words = [lemmatizer.lemmatize(word, pos_map.get(pos[0], wordnet.NOUN)) for word, pos in pos_tags]\n",
        "\n",
        "    # Stemming\n",
        "    stemmed_words = [stemmer.stem(word) for word in lemmatized_words]\n",
        "\n",
        "    return ' '.join(stemmed_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQwS9xSUTgzH",
        "outputId": "1ccf0d5e-6a2a-41a7-bf12-7e78b072f472"
      },
      "outputs": [],
      "source": [
        "data_ids = []\n",
        "column_manual = []\n",
        "column_llama = []\n",
        "column_qwen = []\n",
        "column_qwen_coder = []\n",
        "descriptions = {}\n",
        "manual = {}\n",
        "llama = {}\n",
        "\n",
        "with open('descriptions.csv', 'r', encoding='utf-8') as desc_file:\n",
        "    desc_reader = csv.reader(desc_file, delimiter=',')\n",
        "    next(desc_reader)\n",
        "    for row in desc_reader:\n",
        "        descriptions[row[0]] = row[1]\n",
        "\n",
        "with open('input.csv', 'r', encoding='utf-8') as csv_file:\n",
        "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "    next(csv_reader)\n",
        "    for row in csv_reader:\n",
        "        data_ids.append(row[0])\n",
        "        manual[row[0]] = row[1]\n",
        "        llama[row[0]] = row[2]\n",
        "        column_manual.append(text_cleaning(row[1]))\n",
        "        column_llama.append(text_cleaning(row[2]))\n",
        "        column_qwen.append(text_cleaning(row[3]))\n",
        "        column_qwen_coder.append(text_cleaning(row[4]))\n",
        "\n",
        "def calculate_bleu_stats(column_manual, column_model, weights):\n",
        "    scores = []\n",
        "    for i in range(len(column_manual)):\n",
        "        if not column_manual[i] and not column_model[i]:\n",
        "            scores.append(1.0)\n",
        "        else:\n",
        "            scores.append(sentence_bleu([column_manual[i]], column_model[i], weights=weights))\n",
        "\n",
        "    average = round(sum(scores) / len(scores), 4)\n",
        "    median = round(statistics.median(scores), 4)\n",
        "    highest = round(max(scores), 4)\n",
        "    lowest = round(min(scores), 4)\n",
        "    overall_range = round(highest - lowest, 4)\n",
        "\n",
        "    below_03 = [s for s in scores if s < 0.3]\n",
        "    between_03_05 = [s for s in scores if 0.3 <= s < 0.5]\n",
        "    above_05 = [s for s in scores if s >= 0.5]\n",
        "    total = len(scores)\n",
        "\n",
        "    def get_range(category_scores):\n",
        "        return round(max(category_scores) - min(category_scores), 4) if category_scores else 0.0\n",
        "\n",
        "    distribution = {\n",
        "        \"<0.3\": {\"count\": len(below_03), \"percentage\": round((len(below_03) / total) * 100, 2), \"range\": get_range(below_03)},\n",
        "        \"0.3 to <0.5\": {\"count\": len(between_03_05), \"percentage\": round((len(between_03_05) / total) * 100, 2), \"range\": get_range(between_03_05)},\n",
        "        \">=0.5\": {\"count\": len(above_05), \"percentage\": round((len(above_05) / total) * 100, 2), \"range\": get_range(above_05)}\n",
        "    }\n",
        "\n",
        "    print(\"Distribution:\")\n",
        "    for category, data in distribution.items():\n",
        "        print(f\"  {category}: Count = {data['count']}, Percentage = {data['percentage']}%, Range = {data['range']}\")\n",
        "\n",
        "    return {\n",
        "        \"average\": average,\n",
        "        \"median\": median,\n",
        "        \"highest\": highest,\n",
        "        \"lowest\": lowest,\n",
        "        \"overall_range\": overall_range,\n",
        "        \"scores\": scores,\n",
        "        \"distribution\": distribution\n",
        "    }\n",
        "\n",
        "def compute_bleu_scores(column_manual, column_llama, column_qwen, column_qwen_coder):\n",
        "    models = {\"Llama\": column_llama, \"Qwen\": column_qwen, \"Qwen-Coder\": column_qwen_coder}\n",
        "    weights_list = {\"BLEU-1\": (1.0, 0, 0, 0), \"BLEU-2\": (0.5, 0.5), \"BLEU-3\": (0.33, 0.33, 0.33), \"BLEU-4\": (0.25, 0.25, 0.25, 0.25)}\n",
        "\n",
        "    results = {}\n",
        "    for model_name, column_model in models.items():\n",
        "        results[model_name] = {}\n",
        "        for bleu_name, weights in weights_list.items():\n",
        "            stats = calculate_bleu_stats(column_manual, column_model, weights)\n",
        "            results[model_name][bleu_name] = stats\n",
        "            print(f\"{model_name} {bleu_name} - Avg: {stats['average']}, Median: {stats['median']}, Highest: {stats['highest']}, Lowest: {stats['lowest']}, Overall Range: {stats['overall_range']}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "results = compute_bleu_scores(column_manual, column_llama, column_qwen, column_qwen_coder)\n",
        "\n",
        "def get_low_bleu_ids(threshold=0.3):\n",
        "    low_bleu_ids = [data_ids[i] for i in range(len(data_ids)) if all(results[model]['BLEU-2']['scores'][i] < threshold for model in results)]\n",
        "    return low_bleu_ids\n",
        "\n",
        "low_bleu_ids = get_low_bleu_ids()\n",
        "print(f\"Number of IDs with low BLEU scores: {len(low_bleu_ids)}\")\n",
        "print(\"Low BLEU IDs:\", low_bleu_ids)\n",
        "\n",
        "with open('low_bleu_data_updated.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
        "    csv_writer = csv.writer(csvfile)\n",
        "    csv_writer.writerow([\"ID\", \"Description\", \"Manual\", \"Llama\"])\n",
        "    for id in low_bleu_ids:\n",
        "        csv_writer.writerow([id, descriptions.get(id, \"\"), manual.get(id, \"\"), llama.get(id, \"\")])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
